{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lt52D_8fL8p"
      },
      "source": [
        "# ASL Translation\r\n",
        "The aim of this project is to identify the ASL symbols shown in a webcam. This project uses the concept of Image Processing to identify the images. <br>\r\n",
        "This is a part of the project to build a personal assistant that can take commands using ASL. This will be greatly useful for the people who have trouble hearing. <br>\r\n",
        "This model has been trained to identify 6 letters, for the following commands. The personal assistant that has been used is Alexa. <br>\r\n",
        "A -> setting an alarm <br>\r\n",
        "D -> volume down <br>\r\n",
        "H -> Hi! <br>\r\n",
        "J -> Tell me a joke. <br>\r\n",
        "T -> setting a timer <br>\r\n",
        "U -> volume Up <br>\r\n",
        "W -> weather <br>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q_DjcagbRxt_",
        "outputId": "8c620ab6-d2a6-4ac7-fc2e-ffe2024ac83c"
      },
      "source": [
        "#mounting the Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, drive\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IganBxmUwr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3063c75f-19dd-4368-bc12-6c4d4225a312"
      },
      "source": [
        "#setting the line breaks in the output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "  \n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGRQhBoogQA_"
      },
      "source": [
        "This model has been developed using tensorflow and keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8sdYOMU4bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "292e6b3f-ddb6-4f36-9513-634391d449dc"
      },
      "source": [
        "#importing the libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuqu10qveQxU"
      },
      "source": [
        "BASE_DIR = \"path to the images directory\"\r\n",
        "LETTERS = [\"A\", \"D\", \"H\", \"J\", \"T\", \"U\", \"W\"]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE0sGsC7iUs6"
      },
      "source": [
        "#checking for gpu\r\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubB1hzt1ihXD"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5ZB2-yzVndn"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiIVngSJgi5H"
      },
      "source": [
        "The images are loaded from the folder in the Google drive. They are preprocessed and converted to a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7gqL309Zn2Ps",
        "outputId": "78f5253f-98e5-4237-aeea-bde102b32802"
      },
      "source": [
        "#variables to hold the images and their labels\n",
        "X = []\n",
        "y =[]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VthTX-lEhAh2"
      },
      "source": [
        "def preprocess_img(img: np.array)-> np.array:\r\n",
        "  \"\"\"\r\n",
        "  A function to preprocess the RGB image\r\n",
        "\r\n",
        "  This function resizes the image and applies the Canny Edge detection algorithm to it. It then converts\r\n",
        "  the image back to RGB scale.\r\n",
        "\r\n",
        "  Args:\r\n",
        "  img: numpy array representation of image\r\n",
        "\r\n",
        "  Returns:\r\n",
        "  A numpy array of the image after preprocessing\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #resizing the image to 299x299\r\n",
        "  img = cv2.resize(img, (299,299))\r\n",
        "\r\n",
        "  #applying the Canny edge detector\r\n",
        "  img = cv2.Canny(img, 40,110)\r\n",
        "\r\n",
        "  #converting the grayscale image back to RGB\r\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7WosLKo9jYO"
      },
      "source": [
        "for ind, alpha in enumerate(LETTERS):\n",
        "  #path of the images of each letter is of the form BASE_DIR/alpha. \n",
        "  current_dir = BASE_DIR+\"/\"+alpha\n",
        "  \n",
        "  #getting the file names in the directory\n",
        "  file_list = list(os.listdir(current_dir))\n",
        "\n",
        "  for fname in file_list:\n",
        "    #reading the image\n",
        "    img = cv2.imread(os.path.join(current_dir, fname), 1)\n",
        "\n",
        "    #preprocessing\n",
        "    img = preprocess_img(img)\n",
        "\n",
        "    #adding the numpy array to X\n",
        "    X.append(img)\n",
        "    #adding the corresponding label to y\n",
        "    y.append(ind)\n",
        "\n",
        "  #checking the progress\n",
        "  print(\"done with \", alpha)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2LwzZAq9jeP"
      },
      "source": [
        "#converting X and y to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWg-6sEf9jbM"
      },
      "source": [
        "#splitting into train and validation sets. Here, 85% of the data is used for training and 15% for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQCcJsBO9jVk"
      },
      "source": [
        "print(\"Training set size: \", X_train.shape)\n",
        "print(\"Test set size: \", X_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "l76_jaTOEpOy",
        "outputId": "30ba1e75-8e2a-4a36-f3f4-44f878cce1a7"
      },
      "source": [
        "#verifying that the data distribution is uniform\n",
        "train_set_labels = dict(Counter(y_train))\n",
        "val_set_labels = dict(Counter(y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KgdQFl4FIcZ"
      },
      "source": [
        "print(train_set_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D6Nx4l5FMkA"
      },
      "source": [
        "print(val_set_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSEcnn2YmkGH"
      },
      "source": [
        "displaying a pie chart of the data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxwxO5y5lUuX"
      },
      "source": [
        "train_keys = list(train_set_labels.keys())\r\n",
        "train_values= list(train_set.values())\r\n",
        "\r\n",
        "fig = plt.figure(figsize =(10, 7)) \r\n",
        "plt.pie(train_keys, labels = train_values) \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWEGRB7PlUrP"
      },
      "source": [
        "val_keys = list(val_set_labels.keys())\r\n",
        "val_values= list(val_set.values())\r\n",
        "\r\n",
        "fig = plt.figure(figsize =(10, 7)) \r\n",
        "plt.pie(val_keys, labels = val_values) \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q04HdUawW_2V"
      },
      "source": [
        "# Developing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3lx3larjYk8C",
        "outputId": "41b5b3c3-0773-4c88-e21a-ce0cda6106b3"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ij_HCxaVpcFv",
        "outputId": "15c5b05a-ec72-4a13-8e78-238cce5b9904"
      },
      "source": [
        "#since this is a image processing task, CNN model has been used.\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# 1st CONV block\n",
        "model.add(tf.keras.layers.Input(shape = (160,160,3)))\n",
        "model.add(Conv2D(64, kernel_size=(5,5), strides=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd CONV block\n",
        "model.add(Conv2D(128, kernel_size=(3,3), strides=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# 3rd CONV block\n",
        "model.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected layers\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "#since there are 7 classes, output layer with 7 units and a softmax activation function\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5XHnezRqGsA"
      },
      "source": [
        "#getting the model summary\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RUHXQmh3YUaL",
        "outputId": "c1882362-ca05-49ce-8849-494dbe27ffc0"
      },
      "source": [
        "#backpropagation algorithm used is Adam with a lr of 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "#compiling the model with categorical_crossentropy function\n",
        "model.compile(optimizer = optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YbDye9DnFbqc",
        "outputId": "4fad3249-35eb-46e4-bee2-7bcc3fdf311f"
      },
      "source": [
        "#converting the y matrices to one-hot vectors\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train)\n",
        "y_val_one_hot = tf.keras.utils.to_categorical(y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImUFRdMGY_Bp"
      },
      "source": [
        "#training the model\n",
        "history = model.fit(x= X_train, y= y_train_one_hot, batch_size=64,\n",
        "                    epochs = 15, verbose = 1, \n",
        "                    validation_data = (X_val, y_val_one_hot), shuffle=True, \n",
        "                    validation_batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPVxDUZeez-u"
      },
      "source": [
        "# Evaluating the model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f5oygpo-zgiL",
        "outputId": "437f6966-8ddf-4d22-a2e3-1d8bd49daa88"
      },
      "source": [
        "#getting the predictions of the model on the validation set\r\n",
        "pred_labels = np.argmax(model.predict(X_val), axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5quyhhjzyE7"
      },
      "source": [
        "# confusion matrix of the predictions\n",
        "print(confusion_matrix(y_val, pred_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqlTuLaMzx58"
      },
      "source": [
        "#classification report of precision-recall values, f1 score \n",
        "print(classification_report(y_val, pred_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C89kPb3Gw9rY"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gls6WgE7yNvP",
        "outputId": "25c58d67-e426-42ef-97d2-9fe2cb77e9a6"
      },
      "source": [
        "def predict_asl_sign(file_path: str)-> None:\n",
        "  \"\"\"\n",
        "  A function to detect the ASL sign in the image\n",
        "\n",
        "  Args:\n",
        "  file_path: A string which is the filename to be processed.\n",
        "\n",
        "  Returns:\n",
        "  It returns None. It displays the predicted class value.\n",
        "  \"\"\"\n",
        "\n",
        "  img = cv2.imread(file_path,1)\n",
        "  img = preprocess_img(img)\n",
        "\n",
        "  #displaying the image\n",
        "  plt.imshow(img)\n",
        "\n",
        "  #reshaping to be fed into the model\n",
        "  img = np.reshape(img, (1,299,299,3))\n",
        "\n",
        "  #getting the predictions\n",
        "  pred_class = np.argmax(model2.predict(img), axis=-1)\n",
        "\n",
        "\n",
        "  print(\"result: \", pred_class)\n",
        "  print(\"letter is: \", letters[pred_class[0]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9dWmJ5QxOvz"
      },
      "source": [
        "predict_asl_sign(\"/content/A.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2TBU0n3x7uv"
      },
      "source": [
        "predict_asl_sign(\"/content/D.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UozWiaZBzBef"
      },
      "source": [
        "predict_asl_sign(\"/content/H.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP3EE8mQsV_W"
      },
      "source": [
        "predict_asl_sign(\"/content/T.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkM6cZh8yyEf"
      },
      "source": [
        "predict_asl_sign(\"/content/U.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idh1GvWxc0gb"
      },
      "source": [
        "predict_asl_sign(\"/content/W.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
